---
author: "Michael Dewey"
slug: "intro-hypothesis-testing"
date: "2020-11-23"
output: 
  blogdown::html_page
tags:
  - Rstats
  - statistics
categories:
  - Lessons
title: "Introduction to Hypothesis Testing"
draft: true
runtime: shiny
---
This lesson is intended to bring together many disparate but crucial elements
of statistics to explain how and why hypothesis testing works. The full version
is intended for students in their first undergraduate statistics course and 
takes around an hour to deliver in tutoring. However, more of the details
can easily be asserted for students in less rigorous courses, allowing this 
lecture to be delivered to high school students.

### Why Do We Test Hypotheses?
Throughout your statistics education, you have doubtless heard much about the 
**parameters** of a probability distribution within a population. In the view of
this lesson^[This refers to the frequentist view as opposed to a Bayesian one], 
the population's parameters are constant values which are *unknown* to us. To set 
an example which will persist throughout this lesson, consider the normal distribution.
The normal distribution is referred to in common parlance as the "bell curve"; we 
denote a population which has that distribution by writing

$$ X_i \stackrel{\text{iid}}{\text{~}} \mathcal{N}(\mu, \sigma^2) $$
The phrase "iid" means **independent and identically distributed**. In short, 
everyone in this population follows the same distribution, and all of the observations
are independent from one another. The assumption of independence is quite important
for some results that follow, so it's necessary to keep it in mind. The parameters
$\mu$ and $\sigma^2$ are the mean and the variance of the normal distribution^[
For the sake of generality, it's worth noting that that is a particular property
of the normal distribution. Other distributions, like the binomial, have parameters
which are not the distribution's mean or variance.]

If we knew the value of the parameters $ \mu $ and $ \sigma^2 $, then we would fully 
know the distribution, meaning that we would perfectly know the probability
of having any value from that distribution. To see this in action, you can play
around with the normal distribution below:

<!--
This is going to be really cool once I get it to work, I swear
<iframe height="800" width="100%" frameborder="no" src="https://michael-dewey.shinyapps.io/normal_distribution/"> </iframe>
-->

In truth, we will never perfectly know the values of the population, although we 
will assume that we know the variance at times. Hypothesis testing, then, is an
exercise in understanding what conclusions we can make about values we will never
know only by using values that we *do* know.

### A Preliminary Example: Repeated Coin Tosses
To wrap your head around how hypothesis testing works on a mechanical level, consider
the following example. I hand you a coin with two sides, heads and tails, and I 
tell you that the coin is "fair", meaning that the chances of getting either heads
or tails is 50%. Maybe out of a sense of boredom, or because you don't trust my
assertion^[Statistics is designed for uncertainty, so no offense taken], you flip 
the coin. After ten flips, you find that six of them have come up with heads. 
After seeing those six heads, do you feel that you have enough evidence to reject
my claim that the coin is fair?

You probably shouldn't. It's not that unusual to see six heads out of ten when the
odds are 50-50. In fact, if you were to keep flipping ten times and recording the 
results, around 50% of all of those tests would show a number of heads between
four and six. If you decided to say something along the lines of "I will doubt that
this coin is fair if I see six heads or more" and I **wasn't** lying, there would
still be about a 26% chance that you erroneously doubt me. Which would hurt my
feelings. 

What if, instead, you flipped the coin 100 times, finding that 60 out of those
100 flips came up heads. Would you doubt me then? 

You might, and you'd be on stronger footing to make such a claim. If you kept
repeating this experiment, you'd find that the chance of getting something higher
than 60 heads is only about 2%. If you decided to say something along the lines of
"I will doubt that this coin is fair if I see sixty heads or more" and I wasn't
lying about the coin being 50-50, there would only be a 2% chance that you come
to the wrong conclusion. That's definitely better than 26%!

The important thing to keep in mind, however, is that you will **never** be able
to make a test which is both useful and never makes mistakes of this kind. Hypothesis 
testing asks us to make conclusions based on the data we gathered, which is not the same
thing as seeing the population parameter for ourselves. You will sometimes 
erroneously doubt me. That's okay. The important thing is designing a statement, 
like the ones above, which lower the chance of such a mistake to an acceptable level,
whatever that means for your problem. 

### Formulating Hypotheses
For the sake of illustration, I'll be using the same sets of hypotheses throughout
this page. All throughout, I will make it clear when what I'm saying is not 
general to all hypothesis testing but rather is specific to the hypotheses we
have chosen. We will also focus, for the sake of simplicity, on the case of single
hypothesis testing on the mean of a normal distribution. First, some definitions:
<ul>
  <li> The **null hypothesis**, $H_0$ is a statement of what we believe to be true in 
  the status quo. It is the best guess for a parameter value given common knowledge
  or past information. It is a statement of equality, like $H_0: \mu = 17$
  <li> The **alternative hypothesis** is a statement of what we believe to be
  true if the null hypothesis is not the case. 
  <li> An alternative hypothesis is **simple** if it is a statement of equality,
  such as $H_1: \mu = 20$. For reasons that are not covered here^[The curious reader
  may consult the [Neyman-Pearson Lemma](https://en.wikipedia.org/wiki/Neyman%E2%80%93Pearson_lemma)],
  we will ignore these hypotheses because their associated test is the same as those for
  one-sided alternatives.
  <li> An alternative hypothesis is **one-sided** if it is an inequality statement
  which is exclusively greater or exclusively less than the null hypothesis value.
  For example, a one-sided alternative hypothesis for the null above might be
  $H_1: \mu > 17$, while $H_1: \mu > 19$ would not be. 
  <li> An alternative hypothesis is **two-sided** if it is an inequality on both
  sides. For the null above, this would be stated as $H_1: \mu \not = 17$


As mentioned above, there is no point in using a simple alternative because you
can do just as well with a one-sided alternative which is on the same side of
the mean as the simple value. There's no benefit to being particular in that
sense. Notice that I did not make such a claim when talking about the two-sided
alternative as compared to the one-sided, even though a two-sided test would be
**both** of the one-sided tests at the same time. Take a moment to think about
why this might be the case. That is, why might it true that a two-sided and
one-sided alternative hypothesis each have their own uses? We will come to see
the answer by the end of this post.

Before we move on to understand how we formulate tests, there are two important
notes that close this section.

###### Note 1: We Do Not "Accept The Null"
This point is repeated by every textbook covering hypothesis testing, and for 
good reason. Consider the example above about flipping coins. If you were to 
flip heads 55 times out of 100, you would not have good reason to believe that
the true odds **aren't** 50-50, but you don't necessarily have good evidence that 
it **is** either. Flipping 55 heads out of 100 is also consistent with a slightly
unfair coin, say 55-45 or 60-40. It would be incorrect, then, to say that this
evidence proves that the true odds are 50-50. Instead, it only shows that you don't
have the evidence to prove it isn't 50-50, and hence we say that we "fail to reject
the null". 

###### Note 2: Tests are Fallible

